{
  "text-generator": {
    "version": 1,
    "type": "basic",
    "accumulator-size" : 400000000,
    "embedding": {
      "version": 1,
      "type": "lut",
      "lut-path": "embedding_int8_lut.bin",
      "size": 2048,
      "datatype": "ufixed8",
      "quant-param": {
        "scale": 0.001585477963089943,
        "offset": -129
      }
    },
    "context": {
      "version": 1,
      "size": 4096,
      "n-vocab": 59264,
      "bos-token": -1,
      "eos-token": [
        59246,
        59253,
        59255
      ]
    },
    "tokenizer": {
      "version": 1,
      "path": "tokenizer.json"
    },
    "sampler": {
    	"version": 1,
      "type": "basic",
      "seed": 42,
      "temp": 0.8,
      "top-k": 1,
      "top-p": 0.95
    },
    "engine": {
      "version": 1,
      "n-threads": 3,
      "backend": {
        "version": 1,
        "type": "QnnHtp",
        "QnnHtp": {
          "version": 1,
          "spill-fill-bufsize": 0,
          "use-mmap": true,
          "mmap-budget": 0,
          "poll": false,
          "cpu-mask": "0xe0",
          "kv-dim": 128,
          "allow-async-init": true,
          "enable-graph-switching": true
        },
        "extensions": "htp_backend_ext_config.json"
      },
      "model": {
        "version": 1,
        "type": "binary",
        "binary": {
          "version": 1,
          "ctx-bins": [
            "glm4v_weight_sharing_model_ar32_ar128_cl4096_1_of_2.serialized.bin",
            "glm4v_weight_sharing_model_ar32_ar128_cl4096_2_of_2.serialized.bin"
          ],
          "lora": {
            "version": 1,
            "alpha-tensor-name": "lora_alpha",
            "adapters": [
              {
                "version": 1,
                "name": "ar1_cl4096_1_of_2-ar128_cl4096_1_of_2_default_adapter.bin",
                "bin-sections": [
                  "ar32_cl4096_1_of_2-ar128_cl4096_1_of_2_default_adapter.bin",
                  ""
                ]
              },
              {
                "version": 1,
                "name": "ar1_cl4096_1_of_2-ar128_cl4096_1_of_2_amazon.bin",
                "bin-sections": [
                  "ar32_cl4096_1_of_2-ar128_cl4096_1_of_2_amazon.bin",
                  ""
                ]
              }
            ]
          }
        },
        "positional-encoding": {
          "type": "rope",
          "rope-dim": 64,
          "rope-theta": 10000.0
        }
      }
    }
  }
}
