

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Revision History &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="External Delegate Options" href="../TfLite-Delegate/options.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.35.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="tflite_delegate.html">QNN TFLite Delegate</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Revision History</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Revision History</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="revision-history">
<h1>Revision History<a class="headerlink" href="#revision-history" title="Permalink to this heading">¶</a></h1>
<blockquote>
<div></div></blockquote>
<p>This page contains the change log revision history starting from QAIRT SDK v2.34.0. For details on earlier releases, please refer to ReleaseNotes.txt in QNN_SDK_ROOT for QNN revision history.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 7%" />
<col style="width: 9%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Version</p></th>
<th class="head"><p>Date</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>2.35.0</p></td>
<td><p>May 2025</p></td>
<td><ul class="simple">
<li><p>API: Added LLM support in the Python API. {118016}</p></li>
<li><p>API:Genie: Added a data-alignment-size configuration option for dialog and embeddings APIs. {130270}</p></li>
<li><p>API:Genie: Introduced the GeniePipeline.h and GenieNode.h APIs, providing multimodal support. {123389}</p></li>
<li><p>API:Genie: Introduced the GenieTokenizer.h API. {126408}</p></li>
<li><p>API:HTP: Added support for new memory buffer types (<cite>QNN_HTP_MEM_WEIGHTS_BUFFER</cite> and <cite>QNN_HTP_MEM_SCRATCH_BUFFER</cite>) in the</p></li>
</ul>
<p><cite>QnnMem_register</cite> and <cite>QnnMem_deregister</cite> APIs. {121766}
- API:HTP: Introduced API changes to support external weights and spillfill buffers. {121760}
- CPU: Added Phi 3 and Phi 3.5 model configurations to the Genie SDK. {134117}
- CPU: Added dangling inputs support in Graph. {134280}
- Core: Added platform information to the JSON output of the context binary utility. {129905}
- Docs: Updated QNN/SNPE documentation to include QCS8625 in the list of supported Snapdragon devices. {134450}
- Genie: Added support for use-mmap on Windows platforms. {116519}
- Genie: Enabled support for multi-modal inference with low latency through the GenIE pipeline, supporting various input/output
modalities and utilizing shared embedding weights. {120507}
- Genie: Removed printing of KPIs to stdout, favoring use of GenieProfile. {123352}
- HTP: Added initial support for multi-core weight sharing during deserialization, including functions to handle VA allocation for
weights per core and passing multi-core metadata. {124612}
- HTP: Added multicore weight sharing support during deserialization to map shared weights to different cores without requiring VA
reservations. {135411}
- HTP: Added support for configuring extended_udma prepare time. {136435}
- HTP: Added support for measuring end-to-end latency in the runtime. {98570}
- HTP: Added support for the <cite>QNN_HTP_CONTEXT_CONFIG_OPTION_DEFER_GRAPH_INIT</cite> context configuration option to postpone graph-related
tasks. {130605}
- HTP: Added support for the <cite>QNN_HTP_CONTEXT_GET_PROP_BUFFER_START_ALIGNMENT</cite> context property to retrieve buffer start alignment.
{134678}
- HTP: Added support for the usage of external weights and scratch buffers on the HTP backend. {121767}
- HTP: Added support to save the transport result for multicore transport during async execution. {132146}
- HTP: Enabled support for dynamic input and output resolution for SD3 on the HTP backend. {105781}
- HTP: Enabled the mmap budget feature for WoS to reduce peak RAM usage during context initialization for GenAI use cases. {131070}
- HTP: Extended binary format support for spill/fill to include external buffers. {136017}
- HTP: Implemented buffer size calculations for the HTP backend, including consideration for graph selection and calculation of
maximum spill/fill buffer size. {121765}
- HTP: Updated the Throughput Net Run (TNR) application to utilize thread_pool utilities for thread management. {113123}
- Op:CPU: Added dynamic dimension support for AvgPool2D. {126775}
- Op:CPU: Added dynamic dimension support for InstanceNorm Op. {101384}
- Op:CPU: Added support for the ‘frame_pad’ parameter in Buffer Op. {133242}
- Op:GPU: Added support for the Cast operation from INT64 to INT32 on Windows. {132750}
- Op:HTP: Added INT16 support for the ElementWiseAsin Op on the HTP backend. {114479}
- Op:HTP: Added support for the MaskedSoftmax Op on the HTP backend for LLM use cases. {110661}
- Op:HTP: Implemented performance optimizations for the Score Filter and NMS operations on the HTP backend. {134740}
- OpDef: Added Op definition for IsInf. {125370}
- SDK: Added an option to enable optrace profiling in the TNR application. {135588}
- SDK: Enabled SNPE, QNN, and QNN delegate support for the QCM8550 platform. {129533}
- Tool:Converter: Added dynamic weights support for the Deconv Op in TensorFlow models. {109713}
- Tool:Converter: Added support for Add, Subtract, Multiply, and Divide operations in Float32 precision for static tensor
manipulation within the G2G IR. {125540}
- Tool:Converter: Added support for ONNX 1.16.1 in the Ubuntu 20.04 (Focal) environment. {134975}
- Tool:Converter: Added support for the Size operation and updated Relu opset versions in the ONNX converter to address unsupported
operations in certain models. {133472}
- Tool:Genie: Introduced the genie-app command-line utility. {123548}
- Tool:HTP: Added support for the HTP MCP Binary format in the <cite>QnnHtpBinaryBufferPrinter</cite> tool, enabling proper parsing and
printing of MCP binaries. {128507}
- API: Allowed passing extra arguments through the Python API’s <cite>ConverterConfig</cite> to underlying modules. {133985}
- API: Fixed an encodings path issue during the build phase with GenAI models using the Python API. {133815}
- API: Fixed an issue where quantized and compiled models failed during execution with the Python API when using default
<cite>CalibrationConfig</cite> values. {134858}
- API: Fixed an issue where the QAIRT Python API failed to load backend libraries (<cite>QnnCpu.dll</cite>/<cite>QnnHtp.dll</cite>) on certain devices.
{134461}
- API: Fixed an issue with the JSON reader setting in QNN profiling on Windows. {134565}
- CPU: Fixed a memory management issue for xnnpack Conv2D nodes. {132710}
- CPU: Fixed an issue where certain models failed during inference due to an invalid layer parameter value resulting from a
GroupNorm operation failure. {135924}
- Core: Fixed cross SoC compatibility issues caused by unsynchronized GpuInfo fields between SocServer and SocUtility. {135786}
- DSP: Fixed a context binary generation issue on OE Linux Platform. {124376}
- DSP: Fixed an issue where <cite>snpe-net-run</cite> failed due to an unavailable runtime. {135399}
- DSP: Fixed inference time regressions observed on HTP_FP16 and HTP backends by propagating DSP architecture characteristics to the
HTP core. {133777}
- GPU: Resolved model verification failures encountered with certain CNN models on the GPU backend, related to Conv Kernel
processing. {130041}
- Genie: Fixed an asynchronous initialization issue for Windows platforms. {135904}
- Genie: Fixed an issue where GenieDialog_save/restore could not be used with GENIE_DIALOG_SENTENCE_REWIND. {135558}
- Genie: Fixed an issue where GenieProfiling data could report invalid initialization time data. {134498}
- Genie: Fixed an issue where stop sequences did not work with GenieDialog_embeddingQuery. {134592}
- HTP: Adjusted max PD size calculation to correctly account for far weights, resolving an issue with unexpected secondary PD
triggers during specific test conditions. {127268}
- HTP: Fixed a Stability issue with Llama 3 3B multicore models by updating the method for setting the mc_spill_fill buffer.
{135253}
- HTP: Fixed a crash occurring in multicore graphs due to incorrect identification of spillfill memory pools by the Hexagon NN API.
{135543}
- HTP: Fixed an issue where <cite>qnn-net-run</cite> failed to open a session due to library loading and device transport instance creation
errors. {135028}
- HTP: Fixed an issue where core information was not correctly captured in optrace for multicore execution. {133797}
- HTP: Fixed an out-of-memory issue occurring when running Llama 3 8B models on a single core without splitting. {134696}
- HTP: Fixed async execution failures observed while running certain models in a multicore configuration with shared buffers.
{135047}
- HTP: Fixed logic in graph switching to prevent a bug. {133794}
- HTP: Fixed multicore async inference failures, including issues observed with Zero copy. {134701}
- HTP: Improved model execution time performance on SM8750, addressing an issue where the execution time KPI was not being met.
{128145}
- HTP: Resolved a graph execution failure issue observed during the async_group_init_llama7b_graph_switch_no_shared_resources test.
{126402}
- HTP: Resolved an issue causing incorrect mapping of test failures in nightly reports. {125884}
- HTP: Resolved an issue leading to a “Failed to deregister ion memory with the backend” log message during multi-threaded HTP
binary execution with shared buffers. {129716}
- HTP: Resolved differences in adapter switch time between Genie and <cite>qnn-net-run</cite> by addressing issues related to graph switching
and power settings. {131776}
- Op:CPU: Fixed TransposeConv2d for asymmetric kernels in Float execution. {133778}
- Op:CPU: Fixed an issue by adding INT8 support for GroupNorm Op. {135932}
- Op:GPU: Fixed accuracy errors with the ReduceSum operation when used with Image2DArray for non-Mean ops and specific dimensions.
{131616}
- Op:GPU: Fixed inference failures in models with Argmax/Argmin Ops. {133052}
- Op:HTP: Added support for LayerNorm when the constant input is FP16 converted to FP32. {131420}
- Op:HTP: Enabled UINT_8 datatype support for the StridedSlice Op on the HTP backend, resolving model conversion and graph
preparation failures. {125597}
- Op:HTP: Fixed accuracy issue for GatherNd Op. {110126}
- Op:HTP: Fixed an accuracy issue with LPBQ convolution for MOE on v73. {133134}
- Op:HTP: Fixed an issue where the Genie output resulted in an infinite loop with WoS by updating the prompt file. {134680}
- Op:HTP: Fixed an issue with high power consumption for DepthwiseConv op with asymmetric stride by optimizing the pattern on the
HTP backend. {133635}
- Op:HTP: Improved accuracy of the Swish Op. {133898}
- Op:HTP: Improved performance of the MatMul Op running on HVX. {135210}
- Op:HTP: Improved the performance of the 5D GridSample Op on the HTP backend for W8A16 quantization. {122831}
- Op:HTP: Improved the performance of the GridSample Op on the HTP backend by addressing tiling and scheduling issues. {126462}
- SDK: Fixed an issue where some models failed at the concat operation during graph preparation. {132887}
- Tool: Added a validation check for float fallback to prevent quantizer failures when encodings or calibration lists are not
provided. {133463}
- Tool: Added support for the <cite>–onnx_batch</cite> and <cite>–tensorflow_batch</cite> options in Hypertuner after QAIRT converter changes. {131064}
- Tool: Eliminated a misleading warning message “Function not called, PrepareLib isn’t loaded!” that would appear when running
<cite>qnn-net-run</cite> successfully on HTP. {122382}
- Tool: Fixed an issue where the <cite>is_symmetric</cite> value for 32-bit bias tensors was incorrectly reset during Float Fallback, causing
failures when the output DLC was passed back to the quantizer. {135379}
- Tool: Fixed quantizer to insert Convert Op for LayerNorm weights with external encoding. {134466}
- Tool: Resolved an issue where <cite>snpe-dlc-graph-prepare</cite> failed for certain models due to incompatible float bitwidths when QParams
were present, particularly in the float fallback path. {130558}
- Tool:Converter: Added a fix for a bug in LayerNorm squeeze_axes. {126234}
- Tool:Converter: Added a pattern to map to expand op to reduce inference time. {132363}
- Tool:Converter: Added a warning message for the Non-Zero Op when the output shape is dynamic. {126185}
- Tool:Converter: Added support for a new einsum equation, expanding the range of supported ONNX models. {133824}
- Tool:Converter: Converter-generated FullyConnected Ops now have 2D input and 2D output. {127049}
- Tool:Converter: Ensured that <cite>ApplyEncodings</cite> is called by the quantizer when <cite>–use_quantize_v2</cite> is provided internally, even if
not on the command line. {133705}
- Tool:Converter: Fixed JSON dumping for 4-bit quantized tensors. {133481}
- Tool:Converter: Fixed KernelScale expansion for scalars in TFLite DeConv dequantization. {128978}
- Tool:Converter: Fixed a bug in NonZero Op translation constant folding. {127165}
- Tool:Converter: Fixed a bug in the squash_node_into_nn_node optimization. {126354}
- Tool:Converter: Fixed a conversion error that occurred when <cite>–float_bitwidth 16</cite> was provided on the command line with existing
quantization parameters. {134716}
- Tool:Converter: Fixed a corner case in the DCE process in the converter to correctly handle node removal based on the number of
consumers of output tensors. {129704}
- Tool:Converter: Fixed an error in the squash_node_into_nn_node optimization. {132836}
- Tool:Converter: Fixed an issue where output nodes for BatchMatMul and BatchMatMulV2 Ops were missing by adding support to convert
them to FullyConnected Op. {127139}
- Tool:Converter: Fixed an issue where the converter failed when using the <cite>–desired_input_layout</cite> argument with the new layout
transform algorithm by unifying its behavior with <cite>custom_io</cite>. {136144}
- Tool:Converter: Fixed an issue with 6D support for Concat and Constant Ops in the frontend, resolving a core dump error during
quantization. {117698}
- Tool:Converter: Fixed incorrect population of the “is_symmetric” flag, ensuring encodings are dumped correctly. {134673}
- Tool:Converter: Fixed issue observed when several GRU share one init hidden status, add UT for bidirectional GRU. {91127}
- Tool:Converter: Resolved an accuracy regression issue related to the <cite>squash_batchnorm</cite> optimization in the converter by ensuring
the optimization correctly handles encodings. {130130}
- Tool:Converter: Skipped adding dummy weights and bias tensors during LayerNorm pattern matching. {128870}
- Tool:Converter:ONNX: Added a fix for axis_format handling in matmul_to_fc translation. {118318}
- Tool:Converter:ONNX: Fixed a model conversion issue with the Resize operation in the ONNX converter. {131677}
- Tool:Converter:ONNX: Fixed an ONNX conversion failure for the Sam2 Image Encoder model by addressing layout format issues for
Matmul node inputs and outputs. {131098}
- Tool:Op:HTP: Optimized the DepthwiseConv op with asymmetric stride to improve performance for specific models. {132474}
- Tool:accuracy_debugger: Corrected a tensor shape issue for the oneshot algorithm with ONNX batch=1; the onnx_batch override option
is no longer accessible. {133915}
- Tool:qairt-accuracy-evaluator: Removed the preproc-file option from the Accuracy Evaluator CLI as it is no longer valid due to the
deprecation of minimal mode. {129278}
- Tool:qnn-onnx-converter: Fixed an issue where static tensor framework trace information was missing for some tensors. {120982}
- Tool:qnn-tensorflow-converter: Added logic to ensure the min-max in TensorFlow FakeQuantPerChannel nodes are symmetric. {118672}
- Tool:quantizer: Fixed an issue with 2-bit weight quantization calculation, resolving incorrect output values. {132048}</p>
</td>
</tr>
<tr class="row-odd"><td><p>2.34.0</p></td>
<td><p>April 2025</p></td>
<td><ul class="simple">
<li><p>API:Genie: Added GenieSampler_registerUserDataCallback API which adds a userData argument to the sampler custom callback. {130164}</p></li>
<li><p>API:Genie: Added <cite>GenieEngine.h</cite>, <cite>GenieDialog_getEngine</cite>, and <cite>GenieDialog_bindEngine</cite> APIs. {126715}</p></li>
<li><p>API:SNPE: Added Java API <cite>setUnconsumedTensorsOutput()</cite>, equivalent to the C/C++ builder API
<cite>Snpe_SNPEBuilder_SetUnconsumedTensorsAsOutputs()</cite> / <cite>SNPEBuilder::setUnconsumedTensorsAsOutputs()</cite>. {125891}</p></li>
<li><p>CPU: Added BOOL support in CPU Concat Op. {130940}</p></li>
<li><p>CPU: Added axes parameter support in L2Norm. {121463}</p></li>
<li><p>DSP:SNPE: Added the ability to display the exact priority of the HVX thread in the log to help identify potential issues related
to HVX concurrency scenarios. {117790}</p></li>
<li><p>Genie: Added KV quantization support for GenAiTransformer backend. {123438}</p></li>
<li><p>Genie: Added a LoRAv3 reference/sample Genie configuration to the SDK examples. {130008}</p></li>
<li><p>Genie: Added the Eaglet dialog type. {126452}</p></li>
<li><p>Genie: Added token-acceptance-rate to the GenieProfile output for some dialog types. {123350}</p></li>
<li><p>Genie: Introduced a performance optimization where logits are sampled using the native datatype output of the model. {121359}</p></li>
<li><p>HTP: Deprecated optrace collection via debug configuration files. Use optrace via profiling instead. {124739}</p></li>
<li><p>HTP: Fixed an issue where the number of items was missing in the multicore callback. {129636}</p></li>
<li><p>HTP: Implemented service call to do dspqueue_close for multicore environments. {126381}</p></li>
<li><p>HTP: Introduced parallel graph execution, enabling concurrent running of multiple graphs on a single HTP core to improve
throughput and resource utilization {89181}</p></li>
<li><p>HTP: Performance improvement for Softmax Op with 32 channels or less. {130819}</p></li>
<li><p>Op:GPU: Added support for GridSample Op. {127898}</p></li>
<li><p>Op:HTP: Optimized DepthWiseConv2d op execution by ensuring it runs on HMX {128655}</p></li>
<li><p>Op:HTP: Optimized DepthwiseConv op performance for an ASR model on SM8750 HTP W8A16. {129860}</p></li>
<li><p>OpDef: Added dynamic shape support for FullyConnected Op. {116235}</p></li>
<li><p>OpDef: Added optional parameter <cite>buffer_padding</cite> to Buffer Op. {125962}</p></li>
<li><p>Tool:Converter: Added support for BQ and LPBQ in JSON serializer and deserializer. {132650}</p></li>
<li><p>Tool:Converter: Added support for quantized DLC files as input to the quantizer module. 1. If all tensors are quantized or
overridden float, return directly. 2. If half-quantized DLC, dequantize the fixed-point tensors back to float before quantization.
3. Quantize all float tensors. {129135}</p></li>
<li><p>Tool:Converter: Added support to trigger Quantizer with float_fallback mode. {129131}</p></li>
<li><p>Tool:Converter: Fixed handling of dynamic input shapes with a more informative error message. {127631}</p></li>
<li><p>Tool:Converter: Introduced a new Converter argument to guide different Converter output export formats: –export_format
[&quot;DLC_DEFAULT&quot;, &quot;DLC_STRIP_QUANT&quot;] {129132}</p></li>
<li><p>Tool:Converter: QAIRT Quantizer now skips quantization steps if float_fallback is specified for an input Quant DLC. {130397}</p></li>
<li><p>Tool:qnn-onnx-converter: Added the <cite>–preserve_onnx_output_order</cite> option to maintain ONNX output order in the converted graph.
{126070}</p></li>
<li><p>QNN Core: Fixed an issue where QNN Savecontext failed for multiple models on Windows platforms due to the inability to find the
graph in the DLC. {130104}</p></li>
<li><p>CPU: Added int32 data datatype for ScatterElements. {126766}</p></li>
<li><p>CPU: Fixed L2Norm to handle multiple axis {127053}</p></li>
<li><p>CPU: Fixed verifier failures for single-layer resize models on ONNX16 framework. {124524}</p></li>
<li><p>CPU: Implemented deep copy of <cite>opConfig</cite> in CPU to prevent model failures. {128204}</p></li>
<li><p>DSP: Fixed an SNPE inference failure due to QnnContext_createFromBinary failing with a memory allocation error. {127804}</p></li>
<li><p>DSP: Fixed an SNPE inference failure where multiple models failed due to errors obtaining input tensor names {127809}</p></li>
<li><p>DSP: Fixed inference failures for specific models on HTP due to network partition issues. {131151}</p></li>
<li><p>GPU: Fixed accuracy error in QnnGpuOperationTestActivationAndroid. {125640}</p></li>
<li><p>GPU: Fixed accuracy error in QnnGpuOperationTestTransposeConvAndroid. {125992}</p></li>
<li><p>GPU: Fixed inference regressions in models having Convolution Op in <cite>gpu_fp16</cite> mode for some devices. {120026}</p></li>
<li><p>Genie: Fixed issue in genie-t2t-run where dialog de-initialization data was not saved. {132621}</p></li>
<li><p>Genie: Fixed issue where GenieEmbedding_generate would return a rank of 0. {131581}</p></li>
<li><p>Genie: Fixed issue where quantized values may overflow or underflow. {125929}</p></li>
<li><p>HTP: Addressed inference time regressions on multiple chipsets for HTP and HTP_FP16 configurations. {128165}</p></li>
<li><p>HTP: Corrected the TransportResult resize function to properly set the number of cores. {132311}</p></li>
<li><p>HTP: Fixed a LayerNorm validation failure by checking rank of bias only if it’s present in LayerNorm Op. {106186}</p></li>
<li><p>HTP: Fixed a Windows compatibility issue related to non-shared weight VA reservation. {130567}</p></li>
<li><p>HTP: Fixed a crash in libQnnHtp.so that occurred in graph switch scenarios involving spill fill buffer sharing. {131575}</p></li>
<li><p>HTP: Fixed a deadlock in <cite>allocateAndMapPersistentSpillFillBuffer()</cite> that occurred due to locking conflicts. {132488}</p></li>
<li><p>HTP: Fixed a hang issue in GenAI TNR tests when using asynchronous group initialization with weight sharing and spill-fill sharing
with weight sharing. {132586}</p></li>
<li><p>HTP: Fixed a multithreaded concurrency issue with LLM and small models that caused a ‘memHandles registration failure’. {131051}</p></li>
<li><p>HTP: Fixed a performance regression for a MobileBERT model that was introduced in a previous release. {132111}</p></li>
<li><p>HTP: Fixed a prepare failure for the L2Norm op with fp16 when the relaxed_precision_flag is not set during converter stage.
{129566}</p></li>
<li><p>HTP: Fixed an issue where QNN HTP inference failed during MC detailed profiling. {132564}</p></li>
<li><p>HTP: Fixed an issue where multiple VA sharing groups caused the error ‘Unable to map reserved buffer for non-shared weights’.
{131009}</p></li>
<li><p>HTP: Fixed an issue where qnn-context-binary-generator would hang, consuming excessive CPU and memory. {126833}</p></li>
<li><p>HTP: Fixed intermittent hangs that occurred during the creation of a context from a binary in concurrent scenarios. {131049}</p></li>
<li><p>HTP: Fixed the checker failures related to the OpPackage example by correcting the include path. {130707}</p></li>
<li><p>HTP: Improved performance to address inference time regressions observed on multiple chipsets. {131073}</p></li>
<li><p>HTP: Resolved an issue related to spill-fill buffer sharing, which caused incorrect output. {124544}</p></li>
<li><p>HTP: Resolved an issue with x86_prepare failures during savecontext. High CPU utilization during graph preparation was addressed.
{125093}</p></li>
<li><p>HTP: Resolved failures in LoRA v2 test cases due to DSP transport call issues, impacting multi-model context and graph switch
scenarios. {130142}</p></li>
<li><p>HTP: Resolved inference time regressions on SM8750. Avoided broadcast overhead on mul_op to improve performance of uint16
elementwise multiplication. {125746}</p></li>
<li><p>HTP: Reverted the enablement of the 64-bit flag to address reported hangs. {130301}</p></li>
<li><p>HTP: Updated PGE support check to use support Features on SoC Model. {127754}</p></li>
<li><p>LPAI: Fixed a failure in LPAI direct mode {131750}</p></li>
<li><p>LPAI: Fixed an issue where LPAI single layer models were failing. {130729}</p></li>
<li><p>Op:DSP: Supported LayerNorm; modified the hard code check. {122112}</p></li>
<li><p>Op:HTP: Added 5D support for float Sigmoid. {128867}</p></li>
<li><p>Op:HTP: Addressed performance issues when converting models with w8a16 compared to w8a8 on SM8350 by optimizing matmul and Gemm
OPs. {121404}</p></li>
<li><p>Op:HTP: Fixed ReduceMax FP16 compilation error. {127900}</p></li>
<li><p>Op:HTP: Fixed a QNN context-binary-generator failure due to a TCM insufficient tile error when processing a custom model. {129510}</p></li>
<li><p>Op:HTP: Fixed context binary generation failures for ArgMin/ArgMax ops due to TCM overflow. {108763}</p></li>
<li><p>Op:HTP: Fixed model validation errors during context saving, specifically addressing issues with the DepthToSpace Op. {131083}</p></li>
<li><p>Op:HTP: Fixed numerical issue for DepthwiseConv2d -&gt; HardSwish in a MobileNetV3 model. {128158}</p></li>
<li><p>Op:HTP: Fixed rank constraints of Op replacement rule. {130194}</p></li>
<li><p>Op:HTP: Improved DepthwiseConv2D performance. {126421}</p></li>
<li><p>Op:HTP: Optimized Reshape Ops when PCQ is enabled on constant tensors going into a MatMul Op, improving performance. {130415}</p></li>
<li><p>Op:HTP: Registered QInt16 for Concat Op to resolve graph preparation failures when using QuantInt16 tensors. {125735}</p></li>
<li><p>Op:HTP: Resolved an issue where context binary size calculation failed during graph preparation. {124130}</p></li>
<li><p>Op:HTP: Resolved an on-device hang issue during execution of Dynamic MobileNet V2, specifically during the Transpose Op {126806}</p></li>
<li><p>Op:HTP: Resolved context binary generation failures for the BevFormer model with AMP encodings. {129991}</p></li>
<li><p>SDK: Fixed build issues in Qnn SampleApp, Qnn SampleAppAsyncExecution and Qnn SampleAppSharedBuffer. {131442}</p></li>
<li><p>SDK: Removed “pytorch to onnx conversion avoidance suggestions” from QNN SDK Docs. {132125}</p></li>
<li><p>SDK: <cite>ReleaseNotes.txt</cite> renamed to <cite>QAIRT_ReleaseNotes.txt</cite> and now contains release notes for both Unix and WoS. {127817}</p></li>
<li><p>SNPE: Fixed API <cite>Snpe_SNPEBuilder_SetInitCacheMode()</cite>/<cite>SNPEBuilder::setInitCacheMode()</cite> breakage for non-HTP backends when using
the <cite>snpe-net-run</cite> option <cite>–enable_init_cache</cite>. {129545}</p></li>
<li><p>SNPE: Fixed the <cite>–enable_init_cache</cite> option (API <cite>SNPEBuilder::setInitCacheMode()</cite>/<cite>Snpe_SNPEBuilder_SetInitCacheMode()</cite>) in
<cite>net-run</cite> for AIP runtime. {131929}</p></li>
<li><p>Tool:Converter: Corrected an issue where qnn-context-binary-generator logged an incorrect QPC path when the –backend_binary
option was used. {126169}</p></li>
<li><p>Tool:Converter: Corrected the allowed length for pad amounts for 4D tensors in the emitter. {132185}</p></li>
<li><p>Tool:Converter: Enabled data invariant optimizations for the Tile Op. If the input of Tile Op is quantized, the input dataType and
qInfo are copied to the output. {126372}</p></li>
<li><p>Tool:Converter: Fixed Layout Transform to avoid unintentionally loading deferred weights. {132173}</p></li>
<li><p>Tool:Converter: Fixed a segfault issue in IrJsonDeserializer during deserialization of newly generated model JSON files. {129816}</p></li>
<li><p>Tool:Converter: Fixed an issue where Accuracy Evaluator runs failed at the Netrun stage. {129997}</p></li>
<li><p>Tool:Converter: Fixed an issue where FOLD_MULTIPLE_TRANSPOSE was incorrectly pruning graph outputs. {127963}</p></li>
<li><p>Tool:Converter: Fixed an issue where context binary generation failed with a ‘Graph Finalize failure’ when using multi-Qranium
pipelined partitioning. {124908}</p></li>
<li><p>Tool:Converter: Fixed an issue where qnn-context-binary generation failed for LVM UNet models due to tensor updateability and
GroupNorm Op validation errors with the HTP backend. {127887}</p></li>
<li><p>Tool:Converter: Fixed an issue where the qnn-context-binary-generator tool failed on Windows-X86 when processing LoRAv3 models.
{130894}</p></li>
<li><p>Tool:Converter: Fixed index error failure in remove identity optimization. {125867}</p></li>
<li><p>Tool:Converter: Fixed issue when folding multiple transposes to retain graph output names. {128685}</p></li>
<li><p>Tool:Converter: Resolved a serialization issue with MatMul ops involving int16*int16 data types when using dynamic 16-bit weights.
{129733}</p></li>
<li><p>Tool:Converter:ONNX: Added support for dynamic inputs for Clip Op. {124203}</p></li>
<li><p>Tool:Converter:ONNX: Fixed an issue in the Converter to ensure correct name sanitization following C++ naming conventions.
{129356}</p></li>
<li><p>Tool:Converter:ONNX: Fixed axis tracking in ScatterElements. {118614}</p></li>
<li><p>Tool:Converter:ONNX: Fixed issue for reverse GRU Op to ensure the correct order of input names for the first output. {130544}</p></li>
<li><p>Tool:Converter:ONNX: Updated translation for ExpandOp to reduce inference time. {127065}</p></li>
<li><p>Tool:qairt-accuracy-evaluator: Fixed issue where the input list was incorrectly passed to the quantizer. {130537}</p></li>
<li><p>Tool:qairt-accuracy-evaluator: - Added support for the ‘algorithms’ quantizer parameter in the evaluator. - Provided input shape
to the converter for PyTorch models. {126291}</p></li>
<li><p>Tool:qnn-accuracy-debugger: Enhanced the qnn-accuracy-debugger tool to provide more meaningful metrics for intermediate tensor
cosine similarity. {126437}</p></li>
<li><p>Tool:qnn-net-run: Resolved an issue in accuracy evaluator runs where the error “‘Namespace’ object has no attribute
‘preserve_graph_output_order’” was encountered. {132180}</p></li>
<li><p>Tool:qnn-onnx-converter: Aligned the ONNX Resize Op translator’s behavior with ONNX definitions. {123092}</p></li>
<li><p>Tool:snpe-architecture-checker: Fixed an issue where snpe-architecture-checker would fail due to an uninitialized variable.
{126778}</p></li>
<li><p>Tool:snpe-stress-net-run: Fixed a memory leak issue when loading QNN models. {128498}</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../TfLite-Delegate/options.html" class="btn btn-neutral float-left" title="External Delegate Options" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2025, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>